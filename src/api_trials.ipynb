{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from canvas_data.api import CanvasDataAPI\n",
    "import pandas as pd\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "API_KEY = \"ef6e4a2c602ecea8a0786a458c0cb3e6b400af81\"\n",
    "API_SECRET =\"fa2308e9070428c33dbcc4e096df5983488f1aa9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "class Extract():\n",
    "\n",
    "    def __init__(self, API_KEY, API_SECRET):\n",
    "        from tqdm import tqdm\n",
    "        self.API_KEY = API_KEY\n",
    "        self.API_SECRET = API_SECRET\n",
    "\n",
    "\n",
    "    def connect_canvas_api(self):\n",
    "        from canvas_data.api import CanvasDataAPI\n",
    "        \"\"\"\n",
    "        Function that connects to Canvas API \n",
    "        Returns: \n",
    "            - answer : dict type \n",
    "                contains all the tables in the API  \n",
    "            - conn_str : string \n",
    "                string in case the connection failed \n",
    "        \"\"\"\n",
    "        cd = CanvasDataAPI(api_key=self.API_KEY, api_secret=self.API_SECRET, download_chunk_size=1024*1024)\n",
    "        return cd\n",
    "    \n",
    "    def get_dims_facts(self, schema, tables):\n",
    "        dims, facts = [], []\n",
    "        for table in tables:\n",
    "            table_type = table[-3:]\n",
    "            if table_type == 'dim': \n",
    "                dims.append(table)\n",
    "            else: \n",
    "                facts.append(table)\n",
    "        return dims, facts\n",
    "    \n",
    "    def create_tablenames_files(self): \n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        cd = self.connect_canvas_api()\n",
    "        try:\n",
    "            schema = cd.get_schema('latest', key_on_tablenames=True)\n",
    "            tables = list(schema.keys())\n",
    "            dims, facts = self.get_dims_facts(schema, tables)\n",
    "            directory = f'/Users/larissa.ojeada/thesis-canvas/src/'\n",
    "            dims_file = open(f\"{directory}dims.txt\", \"w\")\n",
    "            for element in tqdm(dims):\n",
    "                dims_file.write(element + \"\\n\")\n",
    "            dims_file.close()\n",
    "            facts_file = open(f\"{directory}facts.txt\", \"w\")\n",
    "            for element in tqdm(facts): \n",
    "                facts_file.write(element + \"\\n\")\n",
    "            facts_file.close()\n",
    "        except:\n",
    "            print(\"Something went wrong creating the files\")        \n",
    "\n",
    "    def unzip_files(self, directory = '/Users/larissa.ojeada/thesis-canvas/src/downloads'):\n",
    "        import os\n",
    "        import pathlib\n",
    "        dir_name = 'unzipped'\n",
    "        new_dir = pathlib.Path(directory, dir_name)\n",
    "        new_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for filename in tqdm(os.listdir(directory)):\n",
    "            try: \n",
    "                filepath = os.path.join(directory, filename)\n",
    "                with gzip.open(filepath, 'rb') as file_in:\n",
    "                    with open(f'{directory}/unzipped/{filename[:-3]}.txt', 'wb') as file_out:\n",
    "                        shutil.copyfileobj(file_in, file_out)\n",
    "            except:\n",
    "                print(f'Could not unzip file {filename[:-3]}')\n",
    "        \n",
    "    def extract_files(self):\n",
    "        cd = self.connect_canvas_api()\n",
    "        try: \n",
    "            files = cd.download_files(dump_id='latest', include_requests=False)\n",
    "            unzip = self.unzip_files()\n",
    "        except Exception as e: \n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:00<00:00, 658525.99it/s]\n",
      "100%|██████████| 52/52 [00:00<00:00, 649118.48it/s]\n"
     ]
    }
   ],
   "source": [
    "API_KEY = \"ef6e4a2c602ecea8a0786a458c0cb3e6b400af81\"\n",
    "API_SECRET =\"fa2308e9070428c33dbcc4e096df5983488f1aa9\"\n",
    "extraction = Extract(API_KEY, API_SECRET)\n",
    "cd = extraction.connect_canvas_api()\n",
    "schema = cd.get_schema('latest', key_on_tablenames=True)\n",
    "tables = list(schema.keys())\n",
    "extraction.create_tablenames_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tablenames_files(self): \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    cd = self.connect_canvas_api()\n",
    "    try:\n",
    "        schema = cd.get_schema('latest', key_on_tablenames=True)\n",
    "        tables = list(schema.keys())\n",
    "        print('im here 1')\n",
    "        dims, facts = get_dims_facts(schema, tables)\n",
    "        print('started dims')\n",
    "        dims_file = open(\"dims.txt\", \"w\")\n",
    "        for element in tqdm(dims):\n",
    "            dims_file.write(element + \"\\n\")\n",
    "        dims_file.close()\n",
    "        print('finished dims')\n",
    "        facts_file = open(\"facts.txt\", \"w\")\n",
    "        for element in tqdm(facts): \n",
    "            facts_file.write(element + \"\\n\")\n",
    "        facts_file.close()\n",
    "        print('finished facts')\n",
    "    except:\n",
    "        print(\"Something went wrong creating the files\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid api key\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    schema = cd.get_schema('latest', key_on_tablenames=True)\n",
    "    tables = list(schema.keys())\n",
    "    dims, facts = get_dims_facts(schema, tables)\n",
    "    print('started dims')\n",
    "    dims_file = open(\"dims.txt\", \"w\")\n",
    "    for element in tqdm(dims):\n",
    "        dims_file.write(element + \"\\n\")\n",
    "    dims_file.close()\n",
    "    print('finished dims')\n",
    "    facts_file = open(\"facts.txt\", \"w\")\n",
    "    for element in tqdm(facts): \n",
    "        facts_file.write(element + \"\\n\")\n",
    "    facts_file.close()\n",
    "    print('finished facts')\n",
    "except:\n",
    "    print(\"Something went wrong creating the files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m schema \u001b[38;5;241m=\u001b[39m cd\u001b[38;5;241m.\u001b[39mget_schema(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest\u001b[39m\u001b[38;5;124m'\u001b[39m, key_on_tablenames\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# obtenemos todas las tablas\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m total_tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tables)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# tables = list(schema.keys())\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# print(tables)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_column_names\u001b[39m(col_details): \n",
      "\u001b[0;31mNameError\u001b[0m: name 'tables' is not defined"
     ]
    }
   ],
   "source": [
    "# schema is dict type that contains all the tables in the API \n",
    "#print(schema)\n",
    "schema = cd.get_schema('latest', key_on_tablenames=True)\n",
    "# obtenemos todas las tablas\n",
    "total_tables = len(tables)\n",
    "# tables = list(schema.keys())\n",
    "# print(tables)\n",
    "\n",
    "\n",
    "def get_column_names(col_details): \n",
    "    col_names = []\n",
    "    for item in col_details:\n",
    "        col_names.append(item['name'])\n",
    "    return col_names\n",
    "\n",
    "def get_columns(schema):\n",
    "    for table in schema:\n",
    "        table_name = table  # could be errased \n",
    "        print(f\"TABLE NAME IS {table_name} \")\n",
    "        col_details = schema[table]['columns'] #brings us all the details about the columns\n",
    "        col_names = get_column_names(col_details)  #column names only (no type)\n",
    "        print(col_names)\n",
    "        #common_cols = get_common_cols(schema, col_names)\n",
    "\n",
    "common_cols = get_columns(schema) \n",
    "#print(common_cols)\n",
    "\n",
    "# not sure if passing the tables is better \n",
    "# given a certain table it returns all the tables that have columns in common \n",
    "# needs an improvement bc the tables have their own id called id \n",
    "# so i have to create that name in order to look for it in the table \n",
    "def get_common_cols(col_names_list1, col_names_list2):\n",
    "    set_list1 = set(col_names_list1)\n",
    "    set_list2 = set(col_names_list2)\n",
    "    #intersection = set_list1.intersection(set_list2)\n",
    "    return set_list1.intersection(set_list2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "- List all the tables separated by dims and facts and their columns \n",
    "- Generate a file with this info separated \n",
    "- Load all files to DB (historical)\n",
    "- Plot and table with DB info (powerBI, python)\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = cd.download_files(dump_id='latest',\n",
    "                          include_requests=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns(schema):\n",
    "    for table in schema:\n",
    "        table_name = table  # could be errased \n",
    "        col_details = schema[table]['columns'] #brings us all the details about the columns\n",
    "        nmbr_cols = len(col_details)  # number of columns per table \n",
    "        cols = get_column_names(col_details)  #column names only (no type)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the dumps \n",
    "dumps = cd.get_dumps()\n",
    "print(type(dumps),len(dumps))\n",
    "print(dumps[0]['dumpId'])  # get the ID of the first listed dump (just trial)\n",
    "# print(dumps)\n",
    "dump_contents = cd.get_file_urls(dump_id='latest')\n",
    "files = cd.download_files(dump_id='latest',\n",
    "                          include_requests=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dump has a certain ID, so we retreive the information of this particular dump \n",
    "# This works similar as the previous elaborated case where you get the URL of the file and you have two ways:\n",
    "#   1. we can do the request manually with requests library or other and store it in folder (save space/efficient)\n",
    "#   2. We can use the API method that gets us ALL the dumps into the download folder\n",
    "#   With both ways we must unzip the '.gz' files and then load it into DB\n",
    "dump_contents = cd.get_file_urls(dump_id='9823978d-de5c-41cd-837a-c73a35e3be98')\n",
    "dumps = cd.get_dumps()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_contents = cd.get_file_urls(dump_id='latest')\n",
    "print(len(dump_contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING WITH DUMPS \n",
    "# trial: uncompress the dumps (the dumps are nightly uploaded, but not all dumps change) \n",
    "with gzip.open('/Users/larissa.ojeada/thesis-canvas/src/downloads/pseudonym_fact-00000-195a2126.gz', 'rb') as file_in:\n",
    "    with open('file.txt', 'wb') as file_out:\n",
    "        shutil.copyfileobj(file_in, file_out) #itworked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dict with info of some dumps (tables) to dataframe to plot in sns \n",
    "data = {'name': ['nick', 'david', 'joe', 'ross'],\n",
    "        'age': ['5', '10', '7', '6']} \n",
    "new = pd.DataFrame.from_dict(data)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# Prints the nicely formatted dictionary\n",
    "pprint.pprint(schema)\n",
    "\n",
    "# Sets 'pretty_dict_str' to the formatted string value\n",
    "pretty_dict_str = pprint.pformat(schema)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
